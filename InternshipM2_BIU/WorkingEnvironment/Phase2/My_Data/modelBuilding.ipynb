{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "436051e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.feature_selection import SelectFromModel, RFE, RFECV\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV, Lasso, LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import r2_score\n",
    "from kennard_stone import train_test_split\n",
    "from sklearn.model_selection import train_test_split as sktrain_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "# from genetic_selection import GeneticSelectionCV\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4284c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDragonDescriptors(family_Y_df, descriptorFileString):\n",
    "    family_X = pd.read_csv(descriptorFileString, sep='\\t', index_col=0)\n",
    "    colsX = family_X.columns\n",
    "    family_X_resetIndex = pd.DataFrame(family_X.to_numpy(), index=family_Y_df.index, columns=family_X.columns).replace('na', np.NaN)\n",
    "    return family_X_resetIndex[colsX[1:]].dropna(axis=1, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c29c731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def remove_low_variance(input_data, threshold=0.1):\n",
    "    selection = VarianceThreshold(threshold)\n",
    "    selection.fit(input_data)\n",
    "    return input_data[input_data.columns[selection.get_support(indices=True)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0f88eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "triph_Y = pd.read_csv('Data/exactPLS/triphenylamines.csv', index_col=0)\n",
    "porph_Y = pd.read_csv('Data/exactPLS/porphyrins.csv', index_col=0)\n",
    "pheno_Y = pd.read_csv('Data/exactPLS/phenothiazines.csv', index_col=0)\n",
    "indol_Y = pd.read_csv('Data/exactPLS/indolines.csv', index_col=0)\n",
    "couma_Y = pd.read_csv('Data/exactPLS/coumarins.csv', index_col=0)\n",
    "carba_Y = pd.read_csv('Data/exactPLS/carbazoles.csv', index_col=0)\n",
    "diphe_Y = pd.read_csv('Data/exactPLS/diphenylamines.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9853a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "triph_X = extractDragonDescriptors(triph_Y, 'Data/exactPLS/desc_triphenylamines.txt')\n",
    "porph_X = extractDragonDescriptors(porph_Y, 'Data/exactPLS/desc_porphyrins.txt')\n",
    "pheno_X = extractDragonDescriptors(pheno_Y, 'Data/exactPLS/desc_phenothiazines.txt')\n",
    "indol_X = extractDragonDescriptors(indol_Y, 'Data/exactPLS/desc_indolines.txt')\n",
    "couma_X = extractDragonDescriptors(couma_Y, 'Data/exactPLS/desc_coumarins.txt')\n",
    "carba_X = extractDragonDescriptors(carba_Y, 'Data/exactPLS/desc_carbazoles.txt')\n",
    "diphe_X = extractDragonDescriptors(diphe_Y, 'Data/exactPLS/desc_diphenylamines.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ff70ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((229, 851),\n",
       " (281, 723),\n",
       " (207, 673),\n",
       " (160, 554),\n",
       " (56, 630),\n",
       " (179, 603),\n",
       " (35, 481))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triph_X.shape,porph_X.shape,pheno_X.shape,indol_X.shape,couma_X.shape,carba_X.shape,diphe_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28b27b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((229, 657),\n",
       " (281, 602),\n",
       " (207, 568),\n",
       " (160, 492),\n",
       " (56, 590),\n",
       " (179, 512),\n",
       " (35, 439))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triph_X_var = remove_low_variance(triph_X, 0.01)\n",
    "porph_X_var = remove_low_variance(porph_X, 0.01)\n",
    "pheno_X_var = remove_low_variance(pheno_X, 0.01)\n",
    "indol_X_var = remove_low_variance(indol_X, 0.01)\n",
    "couma_X_var = remove_low_variance(couma_X, 0.01)\n",
    "carba_X_var = remove_low_variance(carba_X, 0.01)\n",
    "diphe_X_var = remove_low_variance(diphe_X, 0.01)\n",
    "\n",
    "triph_X_var.shape,porph_X_var.shape,pheno_X_var.shape,indol_X_var.shape,couma_X_var.shape,carba_X_var.shape,diphe_X_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5ea5398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnNextRow(rowDf, to_drop):\n",
    "    max = -200\n",
    "    nextRow='None'\n",
    "    for i in range(len(rowDf.columns)):\n",
    "        if (rowDf[rowDf.columns[i]][0] > max) and (rowDf.columns[i] not in to_drop) and (rowDf[rowDf.columns[i]][0] != np.NaN):\n",
    "            max = rowDf[rowDf.columns[i]][0]\n",
    "            nextRow = rowDf.columns[i]\n",
    "    return nextRow\n",
    "\n",
    "def getTo_dropOfRow(rowDf, to_drop=[], threshold=0.95):\n",
    "    for i in range(len(rowDf.columns)):\n",
    "        if (rowDf[rowDf.columns[i]][0] > threshold) and (rowDf[rowDf.columns[i]][0] != np.NaN) and (rowDf.columns[i] not in to_drop):\n",
    "            to_drop.append(rowDf.columns[i])\n",
    "    return to_drop\n",
    "\n",
    "def vWSPFeatureSelect(rowName,corr_matrix,to_drop=[],thresh=0.95):\n",
    "    if rowName=='None':\n",
    "        return to_drop\n",
    "    else:\n",
    "        to_DropThisRow = getTo_dropOfRow(corr_matrix.loc[[rowName]], to_drop, threshold=thresh) #array of column names\n",
    "        nextRow = returnNextRow(corr_matrix.loc[[rowName]], to_DropThisRow)\n",
    "        updateTo_drop = to_DropThisRow\n",
    "        return vWSPFeatureSelect(rowName=nextRow, corr_matrix=corr_matrix,to_drop=updateTo_drop, thresh=thresh)\n",
    "    \n",
    "def vWSP(X_train, threshold=0.95):\n",
    "    cor_matrix = X_train.corr().abs()\n",
    "    upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape), k=1).astype(bool))\n",
    "    to_drop=vWSPFeatureSelect('MW', corr_matrix=upper_tri, to_drop=[], thresh=threshold) #MW chosen as seed\n",
    "    X_train_rm = X_train.drop(to_drop, axis=1)\n",
    "    return X_train_rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0863639f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((229, 486),\n",
       " (281, 444),\n",
       " (207, 407),\n",
       " (160, 345),\n",
       " (56, 424),\n",
       " (179, 395),\n",
       " (35, 257))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triph_X_sansCorr = vWSP(triph_X_var, threshold=0.5)\n",
    "porph_X_sansCorr = vWSP(porph_X_var, threshold=0.5)\n",
    "pheno_X_sansCorr = vWSP(pheno_X_var, threshold=0.5)\n",
    "indol_X_sansCorr = vWSP(indol_X_var, threshold=0.5)\n",
    "couma_X_sansCorr = vWSP(couma_X_var, threshold=0.5)\n",
    "carba_X_sansCorr = vWSP(carba_X_var, threshold=0.5)\n",
    "diphe_X_sansCorr = vWSP(diphe_X_var, threshold=0.5)\n",
    "\n",
    "triph_X_sansCorr.shape,porph_X_sansCorr.shape,pheno_X_sansCorr.shape,indol_X_sansCorr.shape,couma_X_sansCorr.shape,carba_X_sansCorr.shape,diphe_X_sansCorr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdd1f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multipleSplit(input_X, input_Y, test_size=0.3):\n",
    "    familySplits=[]\n",
    "    # 0 --> input_X_train, 1 --> input_X_test, 2 --> input_Y_train, 3 --> input_Y_test\n",
    "    for i in range(10):\n",
    "        familySplits.append(sktrain_test_split(input_X, input_Y['PCE'], test_size=0.3, random_state=i))\n",
    "    return familySplits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "33848f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 486)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triph_split_sets = multipleSplit(triph_X_sansCorr, triph_Y)\n",
    "porph_split_sets = multipleSplit(porph_X_sansCorr, porph_Y)\n",
    "pheno_split_sets = multipleSplit(pheno_X_sansCorr, pheno_Y)\n",
    "indol_split_sets = multipleSplit(indol_X_sansCorr, indol_Y)\n",
    "couma_split_sets = multipleSplit(couma_X_sansCorr, couma_Y)\n",
    "carba_split_sets = multipleSplit(carba_X_sansCorr, carba_Y)\n",
    "diphe_split_sets = multipleSplit(diphe_X_sansCorr, diphe_Y)\n",
    "\n",
    "triph_split_sets[0][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9bbcf4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainOneRF(X_train_X_test_Y_train_Y_test, n_trees=500):\n",
    "    model = RandomForestRegressor(n_estimators=n_trees, max_depth=4)\n",
    "    model.fit(X_train_X_test_Y_train_Y_test[0], X_train_X_test_Y_train_Y_test[2])\n",
    "    predict_train = model.predict(X_train_X_test_Y_train_Y_test[0])\n",
    "    predict_test = model.predict(X_train_X_test_Y_train_Y_test[1])\n",
    "    r2_train = r2_score(X_train_X_test_Y_train_Y_test[2],predict_train)\n",
    "    r2_test= r2_score(X_train_X_test_Y_train_Y_test[3],predict_test)\n",
    "    return r2_train, r2_test\n",
    "\n",
    "def applyMultiRF(multiSplit):\n",
    "    r2_train_scores=[]\n",
    "    r2_test_scores=[]\n",
    "    for i in range(len(multiSplit)):\n",
    "        r2_both = trainPPL_RF(multiSplit[i])\n",
    "        r2_train_scores.append(r2_both[0])\n",
    "        r2_test_scores.append(r2_both[1])\n",
    "    print(f\"All R2 Train:\\n{r2_train_scores}\\n\\nAverage: {np.average(r2_train_scores)}, Std. Dev: {np.std(r2_train_scores)}, Variance {np.var(r2_train_scores)}\\n\\nAll R2 Test:\\n{r2_test_scores}\\n\\nAverage: {np.average(r2_test_scores)}, Std. Dev: {np.std(r2_test_scores)}, Variance {np.var(r2_test_scores)}\")\n",
    "\n",
    "def trainPPL_RF(X_train_X_test_Y_train_Y_test):\n",
    "    rfRegressor = Pipeline([\n",
    "        ('feature_selection', SelectFromModel(RandomForestRegressor(), max_features=X_train_X_test_Y_train_Y_test[0].shape[0])),\n",
    "        ('regression', RandomForestRegressor(n_estimators=500, max_depth=6))\n",
    "    ])\n",
    "    rfRegressor.fit(X_train_X_test_Y_train_Y_test[0], X_train_X_test_Y_train_Y_test[2])\n",
    "    predict_train = rfRegressor.predict(X_train_X_test_Y_train_Y_test[0])\n",
    "    predict_test = rfRegressor.predict(X_train_X_test_Y_train_Y_test[1])\n",
    "    r2_train = r2_score(X_train_X_test_Y_train_Y_test[2],predict_train)\n",
    "    r2_test= r2_score(X_train_X_test_Y_train_Y_test[3],predict_test)\n",
    "    return r2_train, r2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b03a832c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All R2 Train:\n",
      "[0.8397504298420176, 0.8455377745157084, 0.8784896671155281, 0.8669908573080264, 0.8714959265633708, 0.8727318492854703, 0.8557125131997672, 0.8735486034029318, 0.8736882667864991, 0.8900404016410693]\n",
      "\n",
      "Average: 0.8667986289660389, Std. Dev: 0.014607276490478044, Variance 0.00021337252646927256\n",
      "\n",
      "All R2 Test:\n",
      "[0.5144202176817128, 0.5294728249073122, 0.2949728139291896, 0.5048082960072011, 0.3998660821829436, 0.3573067102898221, 0.35244150348297376, 0.57074141413201, 0.45670770389571513, 0.3516269078278016]\n",
      "\n",
      "Average: 0.4332364474336682, Std. Dev: 0.08922834117477889, Variance 0.007961696868802742\n"
     ]
    }
   ],
   "source": [
    "applyMultiRF(triph_split_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ac9fd5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All R2 Train:\n",
      "[0.9236253758632269, 0.9228552080408673, 0.9286371443027728, 0.9204178006355683, 0.9232681288989085, 0.914355645925328, 0.9165947745217463, 0.9237069012364062, 0.9228772985769708, 0.9191001651130112]\n",
      "\n",
      "Average: 0.9215438443114806, Std. Dev: 0.003862647489515929, Variance 1.4920045628263708e-05\n",
      "\n",
      "All R2 Test:\n",
      "[0.5604066938758197, 0.5919986313629078, 0.45746038801552813, 0.6717152608193084, 0.6216752742678225, 0.6817070124690945, 0.6757632949212096, 0.6166584883602305, 0.5832720704578758, 0.6122768334543334]\n",
      "\n",
      "Average: 0.6072933948004131, Std. Dev: 0.06336743255903299, Variance 0.004015431509123594\n"
     ]
    }
   ],
   "source": [
    "applyMultiRF(porph_split_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47cf91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
